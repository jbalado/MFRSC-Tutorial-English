{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd295b9",
   "metadata": {},
   "source": [
    "# Multi Feature-Rich Synthetic Colour (MFRSC) FOR POINT CLOUDS\n",
    "\n",
    "This is a short tutorial to explain step by step the generation of synthetic colour for point clouds from various features according to the paper::\n",
    "\n",
    "- Balado, J., González, E., Rodríguez-Somoza, J. L., & Arias, P. (2023). Multi feature-rich synthetic colour to improve human visual perception of point clouds. ISPRS Journal of Photogrammetry and Remote Sensing, 196, 514-527."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3c64b",
   "metadata": {},
   "source": [
    "# Import of libraries\n",
    "\n",
    "The libraries used in the mathematical morphology are *numpy*, *pyntcloud* and *pandas*.\n",
    "\n",
    "- https://numpy.org/\n",
    "- https://pyntcloud.readthedocs.io/en/latest/#\n",
    "- https://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyntcloud import PyntCloud\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23db57",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "Although there are many point cloud formats, in this tutorial we will start from *txt* clouds, which can be read using *numpy*, as they do not have any compression. The *txt* cloud is structured in 1 point per row and 1 attribute per column, and ' ' is specified as a delimiter between columns. \n",
    "\n",
    "In this case, the input cloud used for colouring contains in this order: \n",
    "- XYZ coordinates (3 columns)\n",
    "- Intensity (1 column)\n",
    "- Return number  (1 column)\n",
    "\n",
    "As a working example a cloud scanned with Mobile Laser Scanner is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading point cloud data\n",
    "input_data = np.loadtxt(\"Nubes/pointcloud_XYZ_I_Rn.txt\", delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235eaf75",
   "metadata": {},
   "source": [
    "# Data extraction and conversion\n",
    "\n",
    "Since colouring is based on features, it is necessary to extract them beforehand. The *pyntcloud* library offers easy and straightforward functions for feature extraction, but it is necessary to first convert the input data to a point cloud object.\n",
    "\n",
    "For those unfamiliar with accessing point cloud data, both in *pandas* and other libraries, access is via [n rows, n columns], such that \":\" indicates that all rows or columns are selected, and numerically \"n:m\" indicates that access is from row/column \"n+1\" to m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinate matrix from input data\n",
    "coord = pd.DataFrame(list(zip(input_data[:,0],input_data[:,1],input_data[:,2])))  \n",
    "\n",
    "# Assign column headings\n",
    "coord.columns =['x', 'y', 'z']\n",
    "\n",
    "# Visualisation\n",
    "print(coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5f37f",
   "metadata": {},
   "source": [
    "Convertir coordenadas a objeto nube de puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion\n",
    "cloud = PyntCloud(coord)\n",
    "\n",
    "# Visualisation\n",
    "print(cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebd6de",
   "metadata": {},
   "source": [
    "# Extraction of features from the input cloud\n",
    "\n",
    "Some of the features using the MFRSC are available directly from the input data:\n",
    "\n",
    "- ***Reflectance intensity*** (Re) is a radiometric feature provided by the LiDAR sensor. The intensity is a widely used to identify surfaces with high reflectivity such as road markings and traffic signs as well as to preserve textures due to variations in material and roughness.\n",
    "\n",
    "- ***Return number*** (Rn) is a radiometric characteristic related to the penetration capacity of the laser in vegetation elements and crystals according to their wavelength. Return number feature is only available in multi-return LiDAR and the maximum number of returns is usually five for new LiDAR systems. This feature is widely used in the identification of vegetation cover.\n",
    "\n",
    "- ***Depth*** (De) is the feature that provides a visualisation of horizontal distances. Depth is a very useful feature to identify objects by their silhouette (difference in distance between target and background).\n",
    "\n",
    "- ***Height*** (He) is a feature provided by the point cloud at Z-coordinate. Height can be measured from sea level, in case of geo-referenced data. In either of these situations, in the subsequent normalization phase, the sea level offset is eliminated. Visualising height as a colour gradient allows the verticality and horizontality of environmental elements to be identified, a principle of human psychology to interpret scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflectance\n",
    "Intens = input_data[:,3]\n",
    "\n",
    "# Return number\n",
    "Return = input_data[:,4]\n",
    "\n",
    "# Depth\n",
    "Depth = np.sqrt(input_data[:,0]**2 + input_data[:,1]**2);\n",
    "\n",
    "# Height\n",
    "Height = input_data[:,2];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469eeb19",
   "metadata": {},
   "source": [
    "# Extraction of features from distances between points\n",
    "\n",
    "For the following set of features it is necessary to calculate the neighbourhoods between points. The neighbourhood is calculated for *k* = 25 neighbours to obtain twin features in the following steps, although for the density only the 5 nearest neighbours are needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of 25 neighbours\n",
    "k_neighbors_25 = cloud.get_neighbors(k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3543307",
   "metadata": {},
   "source": [
    "- ***Point density*** (Pd) is a feature that depends on the laser scanning frequency, the distance between the laser and the target surface and the angle of incidence. It is a relevant feature for highlighting or attenuating isolated points or areas with low point density. In this work we calculate point density based on the distance  between the first (d1) and fourth (d4) closest neighbouring points. This measure was proposed by Pfeifer et al. (2021). However, in order to obtain the delimited values (0–1), the division has been inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689993b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance to first neighbour\n",
    "d1 = np.sqrt(np.sum((input_data[:,0:3]-input_data[k_neighbors_25[:,0],0:3])**2,axis=1))\n",
    "\n",
    "# Distance to the fith neighbour\n",
    "d5 = np.sqrt(np.sum((input_data[:,0:3]-input_data[k_neighbors_25[:,4],0:3])**2,axis=1))\n",
    "\n",
    "# Density calculation\n",
    "Density = d1/d5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c89374",
   "metadata": {},
   "source": [
    "# Extraction of features from normals\n",
    "\n",
    "Knowing the orientation of the surfaces that compose the point cloud is essential for estimating the slope:  \n",
    "\n",
    "- ***Inclination*** (In) is the feature that indicates the orientation of the surface containing the point with respect to the horizon. The inclination is obtained from the calculation of the surface normal of the point regarding to *k* nearest neighbours. The first feature-based recognition model, known as the pandemonium proposed by Selfridge (1988), envisages that the visual system can have detectors of simple geometric features such as vertical, horizontal and oblique lines. Therefore, the visualisation of the inclination of surfaces in the point cloud can help in a more direct recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46816476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal estimation\n",
    "cloud.add_scalar_field(\"normals\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "# Extraction of the normals from the point cloud object\n",
    "normals = cloud.points[[\"nx(26)\", \"ny(26)\", \"nz(26)\"]].to_numpy()\n",
    "\n",
    "# Calculation of inclination\n",
    "Inclination = np.absolute(np.arctan(np.sqrt(normals[:,0]**2+normals[:,1]**2)/normals[:,2]))*180/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb430c2",
   "metadata": {},
   "source": [
    "# Extraction of features from eigenvalues\n",
    "\n",
    "The remaining features are obtained from the eigenvalues of the point cloud:  \n",
    "\n",
    "- ***Linearity*** (Li) is a geometric feature based on the distribution of *k* neighbouring points from the eigenvalues (Weinmann et al., 2015). Linearity enhances linear elements, e.g. pole like objects, but also corners between two planes. According to many object recognition theories, edges are one of the most important features. According to Marr and Nishihara’s theory, in the first stage of perception, the image is described as edges, spots, bars and the geometrical distribution. According to Biederman’s Recognition-by-Components (RBC) theory, geons are simple volumetric shapes and they responsible for object recognition. The first step of recognition would be to extract edges from changes in luminance and, in parallel, the division of the object into concave regions. The RBC/JIM model (Kurbat, 1994; Hummel and Biederman, 1992) consider that recognition occurs in a similar way to neural networks: activation of neurons in successive layers. In the first layer, edges are detected. In layers 2 and 3, geons, symmetry and blobs. In layers 4 and 5, size and orientation of geons. Given the importance of edges, linearity is a very relevant feature for object identification.\n",
    "\n",
    "- ***Planarity*** (Pl) is a geometric feature calculated from the eigenvalues (Weinmann et al., 2015). Planarity enhances flat elements that conform most of the built environment and allow a visualisation of curvature. According to RBC theory, in addition to edge detection, in the construction of 3D representations also are relevant the non-accidental properties (symmetry, parallelism, straightness/curvature and connections), responsible for maintaining the constancy of objects. Therefore, planarity is relevant for identifying geons due to the visualisation of the curvature of the objects.\n",
    "\n",
    "- ***Scattering*** (Sc) is a geometric feature calculated from the eigenvalues (Weinmann et al., 2015). Scattering enhances elements of irregular 3D shapes. This category includes vegetation as well as junctions of three or more planes, so that dispersion is presented as a feature also aligned with edge and geon identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue calculation\n",
    "eigenvalues = cloud.add_scalar_field(\"eigen_values\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "# Geometric feature estimation\n",
    "cloud.add_scalar_field(\"linearity\", ev=eigenvalues)\n",
    "cloud.add_scalar_field(\"planarity\", ev=eigenvalues)\n",
    "cloud.add_scalar_field(\"sphericity\", ev=eigenvalues)\n",
    "\n",
    "# Visualisation of point cloud data\n",
    "cloud.points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ab612",
   "metadata": {},
   "source": [
    "As can be seen from the justification above, there is no one-to-one correspondence between features and perceptual descriptors. Although point cloud features are carefully chosen, many features have interdependencies between them and cover several perceptual descriptors.Interdependences between point cloud features and perception descriptors are shown in the next table:\n",
    "\n",
    "|   | Edges | Texture | Shape | Size | Depth | Orientation |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| Reflectance |   | x | | | | x |\n",
    "| Return number |   | x | | | |  |\n",
    "| Depth | x |  | | x |x | x |\n",
    "| Height | x |  | | x | x | x |\n",
    "| Point density | x  | x | | | | |\n",
    "| Inclination |   |  | x | | | x |\n",
    "| Linearity |  x |  | x | | | |\n",
    "| Planarity |  x |  | x | | | |\n",
    "| Scattering |  x |  | x | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c004046",
   "metadata": {},
   "source": [
    "# Normalisation of features\n",
    "\n",
    "The selected features have different ranges, therefore a normalisation process is necessary to bound the features between 0 and 1. Some features such as density, linearity, planarity, and dispersion are already in this range. For the rest, a normalisation function is applied. For intensity and return number, saturation thresholds must be defined also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab765e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise\n",
    "\n",
    "Intens_n = Intens/1500\n",
    "\n",
    "Return_n = Return/4\n",
    "\n",
    "Depth_n = (Depth-np.min(Depth))/(np.max(Depth)-np.min(Depth))\n",
    "\n",
    "Height_n = (Height-np.min(Height))/(np.max(Height)-np.min(Height))\n",
    "\n",
    "Inclination_n = Inclination/90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c2bb1",
   "metadata": {},
   "source": [
    "# Generation of the feature matrix\n",
    "\n",
    "For convenience,easy channel permutation, and possible later export, the calculated features are put together in a single matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeba67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of features\n",
    "Features = np.column_stack((Intens_n,Return_n,Depth_n,Height_n,Density, cloud.points[['linearity(26)','planarity(26)','sphericity(26)']].to_numpy(),Inclination_n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1db43",
   "metadata": {},
   "source": [
    "# Combination of characteristics per RGB channel\n",
    "\n",
    "There are 362880 possible combinations of all features without repeating them. Evaluating the combination of all of them for each case study takes several hours of processing, so based on the paper presented by the MFRSC, all possible combinations have been tested and an optimal order of features has been suggested. \n",
    "\n",
    "The reduction is done through the conversion of 3 features to 1, according to the RGB to greyscale colour conversion.\n",
    "\n",
    "\n",
    "\n",
    "<center> <img src=\"Figures/F02MFRSC.jpg\"></center>\n",
    "<center> Figure 1. Feature combination, nine to three RGB channels </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB\n",
    "# Depth-Linear-Height\n",
    "R = 0.2989 * Features[:,2] + 0.5870 * Features[:,5] + 0.1140 * Features[:,3];\n",
    "\n",
    "# Return-Reflectance-Inclination \n",
    "G = 0.2989 * Features[:,1] + 0.5870 * Features[:,0] + 0.1140 * Features[:,8];\n",
    "\n",
    "# Planar-Scatter-Density\n",
    "B = 0.2989 * Features[:,6] + 0.5870 * Features[:,7] + 0.1140 * Features[:,4];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf9688",
   "metadata": {},
   "source": [
    "# Export point cloud with MFRSC\n",
    "\n",
    "To save the cloud to disk, the *numpy* library and a *txt* cloud format are used. For saving, an address and name of the file to be generated are specified. The output point cloud contains the geometry (XYZ) of the input cloud and the calculated colours (RGB) in 0-1 scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of path and file name\n",
    "ruta = \"Nubes/pointcloud_MFRSC.txt\"\n",
    "\n",
    "# Data selection \n",
    "output_data = np.column_stack((input_data[:,0:3],R,G,B))\n",
    "\n",
    "# Save\n",
    "np.savetxt(ruta,output_data,delimiter=' ') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd5162",
   "metadata": {},
   "source": [
    "This concludes the tutorial for generating MFRSC for point clouds. I actively recommend downloading the point cloud and viewing it on Cloud Compare. In addition, the last piece of code is the generation of a function for use in your own script without step-by-step explanation or intermediate outputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba931c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFRSC(XYZ,Intens,Return,Sat_Intens, Sat_Rn):\n",
    "    # Extract coordinate matrix from input data\n",
    "    coord = pd.DataFrame(list(zip(XYZ[:,0],XYZ[:,1],XYZ[:,2])))  \n",
    "\n",
    "    # Assign column headings\n",
    "    coord.columns =['x', 'y', 'z']\n",
    "    \n",
    "    # Conversion\n",
    "    cloud = PyntCloud(coord)\n",
    "\n",
    "    # Depth\n",
    "    Depth = np.sqrt(XYZ[:,0]**2 + XYZ[:,1]**2);\n",
    "\n",
    "    # Height\n",
    "    Height = XYZ[:,2];\n",
    "    \n",
    "    # 25 neighbour calculation\n",
    "    k_neighbors_25 = cloud.get_neighbors(k=25)\n",
    "\n",
    "    # Distances\n",
    "    d1 = np.sqrt(np.sum((XYZ[:,0:3]-XYZ[k_neighbors_25[:,0],0:3])**2,axis=1))    \n",
    "    d5 = np.sqrt(np.sum((XYZ[:,0:3]-XYZ[k_neighbors_25[:,4],0:3])**2,axis=1))\n",
    "\n",
    "    # Density\n",
    "    Density = d1/d5\n",
    "\n",
    "    # Surface normals\n",
    "    cloud.add_scalar_field(\"normals\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "    # Extraction of point cloud object normals\n",
    "    normals = cloud.points[[\"nx(26)\", \"ny(26)\", \"nz(26)\"]].to_numpy()\n",
    "\n",
    "    # Inclination\n",
    "    Inclination = np.absolute(np.arctan(np.sqrt(normals[:,0]**2+normals[:,1]**2)/normals[:,2]))*180/np.pi\n",
    "\n",
    "    # Eigenvalues\n",
    "    eigenvalues = cloud.add_scalar_field(\"eigen_values\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "    # Geometric features\n",
    "    cloud.add_scalar_field(\"linearity\", ev=eigenvalues)\n",
    "    cloud.add_scalar_field(\"planarity\", ev=eigenvalues)\n",
    "    cloud.add_scalar_field(\"sphericity\", ev=eigenvalues)\n",
    "\n",
    "    # Normalise\n",
    "    Intens_n = Intens/Sat_Intens\n",
    "    Return_n = Return/Sat_Rn\n",
    "    Depth_n = (Depth-np.min(Depth))/(np.max(Depth)-np.min(Depth))\n",
    "    Height_n = (Height-np.min(Height))/(np.max(Height)-np.min(Height))\n",
    "    Inclination_n = Inclination/90\n",
    "\n",
    "    Features = np.column_stack((Intens_n,Return_n,Depth_n,Height_n,Density, cloud.points[['linearity(26)','planarity(26)','sphericity(26)']].to_numpy(),Inclination_n))\n",
    "\n",
    "    # Depth-Linear-Height\n",
    "    R = 0.2989 * Features[:,2] + 0.5870 * Features[:,5] + 0.1140 * Features[:,3];\n",
    "\n",
    "    # Return-Reflectance-Inclination \n",
    "    G = 0.2989 * Features[:,1] + 0.5870 * Features[:,0] + 0.1140 * Features[:,8];\n",
    "\n",
    "    # Planar-Scatter-Density\n",
    "    B = 0.2989 * Features[:,6] + 0.5870 * Features[:,7] + 0.1140 * Features[:,4];\n",
    "\n",
    "    #Output data \n",
    "    output_data = np.column_stack((XYZ[:,0:3],R,G,B))\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df500d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of application\n",
    "\n",
    "# Select inputs\n",
    "XYZ = input_data[:,0:3]\n",
    "Intens = input_data[:,3]\n",
    "Return = input_data[:,4]\n",
    "\n",
    "# Call to MFRSC function\n",
    "output_data = MFRSC(XYZ,Intens,Return,1500, 4)\n",
    "\n",
    "# Save\n",
    "ruta = \"Nubes/pointcloud_MFRSC.txt\"\n",
    "np.savetxt(ruta,output_data,delimiter=' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9227a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
