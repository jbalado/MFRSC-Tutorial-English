{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd295b9",
   "metadata": {},
   "source": [
    "# Multi Feature-Rich Synthetic Colour (MFRSC) PARA NUBES DE PUNTOS\n",
    "\n",
    "Este es un corto tutorial para explicar paso a paso la generación de color sintético para nube de puntos a partir de diversas características acorde el trabajo:\n",
    "\n",
    "- Balado, J., González, E., Rodríguez-Somoza, J. L., & Arias, P. (2023). Multi feature-rich synthetic colour to improve human visual perception of point clouds. ISPRS Journal of Photogrammetry and Remote Sensing, 196, 514-527."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3c64b",
   "metadata": {},
   "source": [
    "# Importación de librerías\n",
    "\n",
    "Las librerías empleadas en la morfología matemática son *numpy*, *pyntcloud* y *pandas*.\n",
    "\n",
    "- https://numpy.org/\n",
    "- https://pyntcloud.readthedocs.io/en/latest/#\n",
    "- https://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyntcloud import PyntCloud\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23db57",
   "metadata": {},
   "source": [
    "# Lectura de datos\n",
    "\n",
    "Aunque existen numerosos formatos de nubes de puntos, en este tutorial vamos a partir de nubes en formato *txt*, que pueden ser leídas mediante *numpy*, puesto que no tienen ningún tipo de compresión. La nube en *txt* se estructura en 1 punto por fila y un atributo por columna, además se especifica ' ' como delimitador entre columnas. \n",
    "\n",
    "En este caso, la nube de entrada empleada para colorear contiene por este orden: \n",
    "- Coordenadas XYZ\n",
    "- Intensidad\n",
    "- Número de retorno  \n",
    "\n",
    "Como ejemplo de trabajo se proporciona una nube escaneada con Mobile Laser Scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos\n",
    "input_data = np.loadtxt(\"Nubes/pointcloud_XYZ_I_Rn.txt\", delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235eaf75",
   "metadata": {},
   "source": [
    "# Extracción y conversión de datos\n",
    "\n",
    "Dada que el coloreado se basa en características, es necesario previamente extraer algunas de ellas. La librería*pyntcloud* ofrece unas funcionas fáciles y directas para la extracción de características geométricas, pero es necesaria previamente la conversión de los datos de entrada a objeto-nube de puntos.\n",
    "\n",
    "Para los no familiarizados con el acceso a los datos de nubes de puntos, tanto en *pandas* como en otras librerías, el acceso se realiza mediante [n filas, n columnas], de tal forma que con \":\" se indica que se seleccionan todas las filas o columnas, y numéricamente mediante \"n:m\" se indica que se accede desde la fila/columna \"n+1\" a la m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer matriz de coordenadas de los datos de entrada\n",
    "coord = pd.DataFrame(list(zip(input_data[:,0],input_data[:,1],input_data[:,2])))  \n",
    "\n",
    "# Asignar título a columnas\n",
    "coord.columns =['x', 'y', 'z']\n",
    "\n",
    "# Visualización\n",
    "print(coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5f37f",
   "metadata": {},
   "source": [
    "Convertir coordenadas a objeto nube de puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión\n",
    "cloud = PyntCloud(coord)\n",
    "\n",
    "# Visualización\n",
    "print(cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebd6de",
   "metadata": {},
   "source": [
    "# Extracción de características a partir de la nube de entrada\n",
    "\n",
    "Algunas de las características que emplean el MFRSC están disponibles directamente a partir de los datos de entrada:\n",
    "\n",
    "- ***Intensidad de reflectancia*** (Re) es una característica radiométrica proporcionada por el sensor LiDAR. La intensidad se utiliza ampliamente para identificar superficies con alta reflectividad, como marcas viales y señales de tráfico, así como para preservar texturas debido a variaciones en el material y la rugosidad.\n",
    "\n",
    "- ***Número de retorno*** (Rn) es una característica radiométrica relacionada con la capacidad de penetración del láser en elementos vegetales y cristales en función de su longitud de onda. La característica del número de retorno sólo está disponible en LiDAR multirretorno y el número máximo de retornos suele ser cinco en los nuevos sistemas LiDAR. Esta característica se utiliza ampliamente en la identificación de la cubierta vegetal.\n",
    "\n",
    "- ***Profundidad*** (De) es la característica que proporciona una visualización de las distancias horizontales. La profundidad es una característica muy útil para identificar objetos por su silueta (diferencia de distancia entre el objetivo y el fondo).\n",
    "\n",
    "- ***Altura*** (He) es una característica proporcionada por la nube de puntos en coordenada Z. La altura puede medirse desde el nivel del mar, en caso de datos georreferenciados. En cualquiera de estas situaciones, en la fase de normalización posterior se elimina el desfase del nivel del mar. La visualización de la altura como un gradiente de color permite identificar la verticalidad y horizontalidad de los elementos del entorno, un principio de la psicología humana para interpretar las escenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflectancia\n",
    "Intens = input_data[:,3]\n",
    "\n",
    "# Numero retornos\n",
    "Return = input_data[:,4]\n",
    "\n",
    "# Profundidad\n",
    "Depth = np.sqrt(input_data[:,0]**2 + input_data[:,1]**2);\n",
    "\n",
    "# Altura\n",
    "Height = input_data[:,2];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469eeb19",
   "metadata": {},
   "source": [
    "# Extracción de características a partir de distancias entre puntos\n",
    "\n",
    "Para el siguiente conjunto de características es necesario calcular las vecindades entre puntos. La vecindad se calcula para *k* = 25 vecinos para obtener características geométricas en los pasos siguientes, aunque para la densidad solo hacen falta los 5 vecinos más próximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de 25 vecinos\n",
    "k_neighbors_25 = cloud.get_neighbors(k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3543307",
   "metadata": {},
   "source": [
    "- ***Densidad de puntos*** (Pd) es una característica que depende de la frecuencia de barrido láser, la distancia entre el láser y la superficie objetivo y el ángulo de incidencia. Es una característica relevante para resaltar o atenuar puntos aislados o áreas con baja densidad de puntos. En este trabajo calculamos la densidad de puntos basándonos en la distancia entre el primer (d1) y el cuarto (d4) puntos vecinos más cercanos. Esta medida fue propuesta por Pfeifer et al. (2021). Sin embargo, para obtener los valores delimitados (0-1), se ha invertido la división."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689993b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distancia al primer vecino\n",
    "d1 = np.sqrt(np.sum((input_data[:,0:3]-input_data[k_neighbors_25[:,0],0:3])**2,axis=1))\n",
    "\n",
    "# Distancia al quinto vecino\n",
    "d5 = np.sqrt(np.sum((input_data[:,0:3]-input_data[k_neighbors_25[:,4],0:3])**2,axis=1))\n",
    "\n",
    "# Cálculo de densidad\n",
    "Density = d1/d5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c89374",
   "metadata": {},
   "source": [
    "# Extracción de características a partir de normales\n",
    "\n",
    "Conocer la orientación de la superficies que conforman los puntos es fundamental para estimar la inclinación: \n",
    "\n",
    "- ***Inclinación*** (In) es la característica que indica la orientación de la superficie que contiene el punto con respecto al horizonte. La inclinación se obtiene a partir del cálculo de la normal de superficie del punto respecto a *k* vecinos más próximos. El primer modelo de reconocimiento basado en rasgos, conocido como el pandemonio propuesto por Selfridge (1988), prevé que el sistema visual puede disponer de detectores de rasgos geométricos simples, como líneas verticales, horizontales y oblicuas. Por lo tanto, la visualización de la inclinación de las superficies en la nube de puntos puede ayudar a un reconocimiento más directo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46816476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de normales\n",
    "cloud.add_scalar_field(\"normals\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "# Extracción de las normales del objeto nube de puntos\n",
    "normals = cloud.points[[\"nx(26)\", \"ny(26)\", \"nz(26)\"]].to_numpy()\n",
    "\n",
    "# Cálculo de la inclinación\n",
    "Inclination = np.absolute(np.arctan(np.sqrt(normals[:,0]**2+normals[:,1]**2)/normals[:,2]))*180/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb430c2",
   "metadata": {},
   "source": [
    "# Extracción de características a partir de autovalores\n",
    "\n",
    "Las características restantes se obtienen a partir de los autovalores de la nube de puntos:\n",
    "\n",
    "\n",
    "- ***Linealidad*** (Li) es una característica geométrica basada en la distribución de *k* puntos vecinos a partir de los valores propios (Weinmann et al., 2015). La linealidad realza elementos lineales, por ejemplo, objetos similares a postes, pero también esquinas entre dos planos. Según muchas teorías de reconocimiento de objetos, los bordes son una de las características más importantes. Según la teoría de Marr y Nishihara, en la primera etapa de la percepción, la imagen se describe como bordes, manchas, barras y la distribución geométrica. Según la teoría del reconocimiento por componentes (RBC) de Biederman, los geones son formas volumétricas simples y son los responsables del reconocimiento de objetos. El primer paso del reconocimiento consistiría en extraer los bordes a partir de los cambios de luminancia y, paralelamente, la división del objeto en regiones cóncavas. El modelo RBC/JIM (Kurbat, 1994; Hummel y Biederman, 1992) considera que el reconocimiento se produce de forma similar a las redes neuronales: activación de neuronas en capas sucesivas. En la primera capa, se detectan los bordes. En las capas 2 y 3, geones, simetría y manchas. En las capas 4 y 5, tamaño y orientación de los geones. Dada la importancia de los bordes, la linealidad es una característica muy relevante para la identificación de objetos.\n",
    "\n",
    "- ***Planaridad*** (Pl) es una característica geométrica calculada a partir de los valores propios (Weinmann et al., 2015). La planaridad realza los elementos planos que conforman la mayor parte del entorno construido y permiten visualizar la curvatura. Según la teoría RBC, además de la detección de bordes, en la construcción de representaciones 3D también son relevantes las propiedades no accidentales (simetría, paralelismo, rectitud/curvatura y conexiones), responsables de mantener la constancia de los objetos. Por lo tanto, la planaridad es relevante para la identificación de geones debido a la visualización de la curvatura de los objetos.\n",
    "\n",
    "- ***Dispersión*** (Sc) es una característica geométrica calculada a partir de los valores propios (Weinmann et al., 2015). La dispersión realza los elementos de formas 3D irregulares. Esta categoría incluye la vegetación, así como las uniones de tres o más planos, de modo que la dispersión se presenta como una característica también alineada con la identificación de bordes y geones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálulo de autovalores\n",
    "eigenvalues = cloud.add_scalar_field(\"eigen_values\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "# Cálculo de características\n",
    "cloud.add_scalar_field(\"linearity\", ev=eigenvalues)\n",
    "cloud.add_scalar_field(\"planarity\", ev=eigenvalues)\n",
    "cloud.add_scalar_field(\"sphericity\", ev=eigenvalues)\n",
    "\n",
    "# Visualización de los datos\n",
    "cloud.points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ab612",
   "metadata": {},
   "source": [
    "Como se desprende de la justificación anterior, no existe una correspondencia unívoca entre las características y los descriptores perceptivos. Aunque las características de las nubes de puntos se eligen cuidadosamente, muchas de ellas tienen interdependencias entre sí y abarcan varios descriptores perceptuales:\n",
    "\n",
    "|   | Edges | Texture | Shape | Size | Depth | Orientation |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| Reflectance |   | x | | | | x |\n",
    "| Return number |   | x | | | |  |\n",
    "| Depth | x |  | | x |x | x |\n",
    "| Height | x |  | | x | x | x |\n",
    "| Point density | x  | x | | | | |\n",
    "| Inclination |   |  | x | | | x |\n",
    "| Linearity |  x |  | x | | | |\n",
    "| Planarity |  x |  | x | | | |\n",
    "| Scattering |  x |  | x | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c004046",
   "metadata": {},
   "source": [
    "# Normalización de características\n",
    "\n",
    "Las características seleccionadas tienen diferentes rangos, por lo que es necesario un proceso de normalización para acotar los valores entre 0 y 1. Algunas características como la densidad, la linealidad, la planaridad y la dispersión ya se encuentran en este rango. Para el resto, se aplica una función de normalización. Para la intensidad y el número de retorno, a mayores hay que definir umbrales de saturación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab765e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar\n",
    "\n",
    "Intens_n = Intens/1500\n",
    "\n",
    "Return_n = Return/4\n",
    "\n",
    "Depth_n = (Depth-np.min(Depth))/(np.max(Depth)-np.min(Depth))\n",
    "\n",
    "Height_n = (Height-np.min(Height))/(np.max(Height)-np.min(Height))\n",
    "\n",
    "Inclination_n = Inclination/90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c2bb1",
   "metadata": {},
   "source": [
    "# Generación de la matriz de características\n",
    "\n",
    "Para mayor comodidad y posibilidad de una posible exportación posterior, las características calculadas se juntan en una única matriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeba67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de features\n",
    "Features = np.column_stack((Intens_n,Return_n,Depth_n,Height_n,Density, cloud.points[['linearity(26)','planarity(26)','sphericity(26)']].to_numpy(),Inclination_n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1db43",
   "metadata": {},
   "source": [
    "# Combinación de características por canal RGB\n",
    "\n",
    "Existen 362880 posibles combinaciones de todas las características sin repetirlas. Valorar la combinación de todas para cada caso de estudio conlleva varias horas de procesado, por lo que a partir del paper que presenta el MFRSC, se han testeado todas las posibles combinaciones y sugerido un orden óptimo de características.\n",
    "\n",
    "La reducción se realiza mediante la conversión de 3 características a 1, según la conversión de color RGB a escala de grises.\n",
    "\n",
    "\n",
    "\n",
    "<center> <img src=\"Figures/F02MFRSC.jpg\"></center>\n",
    "<center> Figura 1. Combinación de caracteristicas a tres canales RGB  </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB\n",
    "# Depth-Linear-Height\n",
    "R = 0.2989 * Features[:,2] + 0.5870 * Features[:,5] + 0.1140 * Features[:,3];\n",
    "\n",
    "# Return-Reflectance-Inclination \n",
    "G = 0.2989 * Features[:,1] + 0.5870 * Features[:,0] + 0.1140 * Features[:,8];\n",
    "\n",
    "# Planar-Scatter-Density\n",
    "B = 0.2989 * Features[:,6] + 0.5870 * Features[:,7] + 0.1140 * Features[:,4];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf9688",
   "metadata": {},
   "source": [
    "# Exportar nube de puntos con MFRSC\n",
    "\n",
    "Para guardar la nube en disco, se recurre a la librería *numpy* y a un formato de la nube en *txt*. Para el guardado se indica una dirección y nombre del archivo a generar. La nube de puntos de salida contiene la geometría (XYZ) de la nube de entrada y los colores (RGB) calculados en escala 0-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la ruta y nombre del archivo\n",
    "ruta = \"Nubes/pointcloud_MFRSC.txt\"\n",
    "\n",
    "#Selección de datos \n",
    "output_data = np.column_stack((input_data[:,0:3],R,G,B))\n",
    "\n",
    "# Guardado\n",
    "np.savetxt(ruta,output_data,delimiter=' ') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd5162",
   "metadata": {},
   "source": [
    "Con esto concluye el tutorial para generar MFRSC para nubes de puntos. Recomiendo activamente la descarga de la nube y su visualización en Cloud Compare. A mayores, el ultimo fragmento de código es la generación de una función para emplearla en script propios sin explicación paso a paso ni salidas intermedias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba931c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFRSC(XYZ,Intens,Return,Sat_Intens, Sat_Rn):\n",
    "    # Extraer matriz de coordenadas de los datos de entrada\n",
    "    coord = pd.DataFrame(list(zip(XYZ[:,0],XYZ[:,1],XYZ[:,2])))  \n",
    "\n",
    "    # Asignar título a columnas\n",
    "    coord.columns =['x', 'y', 'z']\n",
    "    \n",
    "    # Conversión\n",
    "    cloud = PyntCloud(coord)\n",
    "\n",
    "    # Profundidad\n",
    "    Depth = np.sqrt(XYZ[:,0]**2 + XYZ[:,1]**2);\n",
    "\n",
    "    # Altura\n",
    "    Height = XYZ[:,2];\n",
    "    \n",
    "    # Cálculo de 25 vecinos\n",
    "    k_neighbors_25 = cloud.get_neighbors(k=25)\n",
    "\n",
    "    # Distances\n",
    "    d1 = np.sqrt(np.sum((XYZ[:,0:3]-XYZ[k_neighbors_25[:,0],0:3])**2,axis=1))    \n",
    "    d5 = np.sqrt(np.sum((XYZ[:,0:3]-XYZ[k_neighbors_25[:,4],0:3])**2,axis=1))\n",
    "\n",
    "    # Cáclulo de densidad\n",
    "    Density = d1/d5\n",
    "\n",
    "    # Cálculo de normales\n",
    "    cloud.add_scalar_field(\"normals\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "    # Extracción de las normales del objeto nube de puntos\n",
    "    normals = cloud.points[[\"nx(26)\", \"ny(26)\", \"nz(26)\"]].to_numpy()\n",
    "\n",
    "    # Cálculo de la inclinación\n",
    "    Inclination = np.absolute(np.arctan(np.sqrt(normals[:,0]**2+normals[:,1]**2)/normals[:,2]))*180/np.pi\n",
    "\n",
    "    # Cálulo de autovalores\n",
    "    eigenvalues = cloud.add_scalar_field(\"eigen_values\", k_neighbors=k_neighbors_25)\n",
    "\n",
    "    # Cálculo de características\n",
    "    cloud.add_scalar_field(\"linearity\", ev=eigenvalues)\n",
    "    cloud.add_scalar_field(\"planarity\", ev=eigenvalues)\n",
    "    cloud.add_scalar_field(\"sphericity\", ev=eigenvalues)\n",
    "\n",
    "    # Normalizar\n",
    "    Intens_n = Intens/Sat_Intens\n",
    "    Return_n = Return/Sat_Rn\n",
    "    Depth_n = (Depth-np.min(Depth))/(np.max(Depth)-np.min(Depth))\n",
    "    Height_n = (Height-np.min(Height))/(np.max(Height)-np.min(Height))\n",
    "    Inclination_n = Inclination/90\n",
    "\n",
    "    Features = np.column_stack((Intens_n,Return_n,Depth_n,Height_n,Density, cloud.points[['linearity(26)','planarity(26)','sphericity(26)']].to_numpy(),Inclination_n))\n",
    "\n",
    "    # Depth-Linear-Height\n",
    "    R = 0.2989 * Features[:,2] + 0.5870 * Features[:,5] + 0.1140 * Features[:,3];\n",
    "\n",
    "    # Return-Reflectance-Inclination \n",
    "    G = 0.2989 * Features[:,1] + 0.5870 * Features[:,0] + 0.1140 * Features[:,8];\n",
    "\n",
    "    # Planar-Scatter-Density\n",
    "    B = 0.2989 * Features[:,6] + 0.5870 * Features[:,7] + 0.1140 * Features[:,4];\n",
    "\n",
    "    #Seleccion de datos \n",
    "    output_data = np.column_stack((XYZ[:,0:3],R,G,B))\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df500d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de aplicación\n",
    "\n",
    "# Definir inputs\n",
    "XYZ = input_data[:,0:3]\n",
    "Intens = input_data[:,3]\n",
    "Return = input_data[:,4]\n",
    "\n",
    "# Llamada a MFRSC\n",
    "output_data = MFRSC(XYZ,Intens,Return,1500, 4)\n",
    "\n",
    "# Guardado\n",
    "ruta = \"Nubes/pointcloud_MFRSC.txt\"\n",
    "np.savetxt(ruta,output_data,delimiter=' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
